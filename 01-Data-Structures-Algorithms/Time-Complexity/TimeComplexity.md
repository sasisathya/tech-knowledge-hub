# ğŸ”¹ 1. Why Complexity Analysis?

When we write an algorithm, we want to know:

* **How much time will it take?** (Time Complexity)
* **How much memory will it need?** (Space Complexity)

But we donâ€™t measure in **seconds** (depends on machine, compiler, etc.) â€” instead, we measure **growth with input size (n)**.

---

# ğŸ”¹ 2. Asymptotic Notations

These notations describe how an algorithm behaves as input size grows.

### **Big O (O-notation) â†’ Worst Case**

* **Definition**: Upper bound of time.
* Means â€œin the worst scenario, the algorithm wonâ€™t take longer than this.â€
* Used most often in interviews.

âœ… Example: Linear Search

* Find an element in array of size `n`.
* Worst case = element not found â†’ check all `n`.
* Time = **O(n)**.

---

### **Omega (Î©-notation) â†’ Best Case**

* **Definition**: Lower bound.
* Means â€œat least this much time is needed.â€
* Useful for understanding minimum performance.

âœ… Example: Linear Search

* Best case = element is first â†’ just 1 check.
* Time = **Î©(1)**.

---

### **Theta (Î˜-notation) â†’ Average / Tight Bound**

* **Definition**: Average-case or tight bound.
* Means â€œthe algorithm grows at this rate in general.â€
* If an algorithm always takes about the same time regardless of best/worst â†’ Î˜ is used.

âœ… Example: Linear Search

* On average, element found after `n/2` steps.
* Time â‰ˆ **Î˜(n)**.

---

# ğŸ”¹ 3. Common Time Complexities (Hierarchy)

From best â†’ worst:

1. **O(1)** â†’ Constant time (e.g., accessing array element)
2. **O(log n)** â†’ Logarithmic (binary search)
3. **O(n)** â†’ Linear (traversing array)
4. **O(n log n)** â†’ Linearithmic (merge sort, quicksort avg case)
5. **O(nÂ²)** â†’ Quadratic (nested loops, bubble sort)
6. **O(2â¿)** â†’ Exponential (subset generation, recursion without memoization)
7. **O(n!)** â†’ Factorial (permutations, traveling salesman brute force)

---

# ğŸ”¹ 4. Space Complexity

Same idea, but measures **extra memory** used:

* Variables
* Data structures
* Recursion stack

---
# ğŸ”¹ 6. Quick Rules of Thumb

* Drop **constants**: O(2n) â†’ O(n)
* Drop **non-dominant terms**: O(nÂ² + n) â†’ O(nÂ²)
* Nested loops multiply complexities
* Sequential statements add complexities (O(n) + O(nÂ²) â†’ O(nÂ²))

---

# ğŸ”¹ 7. Summary Table

| Notation | Meaning                | Example            |
| -------- | ---------------------- | ------------------ |
| **O**    | Worst case upper bound | O(n) linear search |
| **Î©**    | Best case lower bound  | Î©(1) linear search |
| **Î˜**    | Tight bound / average  | Î˜(n) linear search |

---
Perfect âœ… â€” hereâ€™s your **DSA Complexity Cheat Sheet (Big O, Î©, Î˜)** ğŸš€
This is a **one-pager style reference** you can keep handy while learning/practicing.

---

# ğŸ“Œ DSA Complexity Cheat Sheet

## ğŸ”¹ Arrays & Strings

| Operation                 | Best (Î©) | Average (Î˜) | Worst (O) |
| ------------------------- | -------- | ----------- | --------- |
| Access element            | Î©(1)     | Î˜(1)        | O(1)      |
| Search (linear)           | Î©(1)     | Î˜(n)        | O(n)      |
| Search (binary, sorted)   | Î©(1)     | Î˜(log n)    | O(log n)  |
| Insert at end (amortized) | Î©(1)     | Î˜(1)        | O(1)      |
| Insert/delete at position | Î©(1)     | Î˜(n)        | O(n)      |
| Reverse string/array      | Î©(n)     | Î˜(n)        | O(n)      |

---

## ğŸ”¹ Searching & Sorting

| Algorithm      | Best (Î©)   | Average (Î˜) | Worst (O)  |
| -------------- | ---------- | ----------- | ---------- |
| Linear Search  | Î©(1)       | Î˜(n)        | O(n)       |
| Binary Search  | Î©(1)       | Î˜(log n)    | O(log n)   |
| Bubble Sort    | Î©(n)       | Î˜(nÂ²)       | O(nÂ²)      |
| Insertion Sort | Î©(n)       | Î˜(nÂ²)       | O(nÂ²)      |
| Selection Sort | Î©(nÂ²)      | Î˜(nÂ²)       | O(nÂ²)      |
| Merge Sort     | Î©(n log n) | Î˜(n log n)  | O(n log n) |
| Quick Sort     | Î©(n log n) | Î˜(n log n)  | O(nÂ²)      |
| Heap Sort      | Î©(n log n) | Î˜(n log n)  | O(n log n) |
| Counting Sort  | Î©(n+k)     | Î˜(n+k)      | O(n+k)     |
| Radix Sort     | Î©(nk)      | Î˜(nk)       | O(nk)      |

---

## ğŸ”¹ Linked List

| Operation              | Best (Î©) | Average (Î˜) | Worst (O) |
| ---------------------- | -------- | ----------- | --------- |
| Search                 | Î©(1)     | Î˜(n)        | O(n)      |
| Insert at head/tail    | Î©(1)     | Î˜(1)        | O(1)      |
| Delete head/tail       | Î©(1)     | Î˜(1)        | O(1)      |
| Insert/delete at index | Î©(1)     | Î˜(n)        | O(n)      |

---

## ğŸ”¹ Stacks & Queues

| Operation       | Best (Î©) | Average (Î˜) | Worst (O) |
| --------------- | -------- | ----------- | --------- |
| Push/Pop        | Î©(1)     | Î˜(1)        | O(1)      |
| Enqueue/Dequeue | Î©(1)     | Î˜(1)        | O(1)      |
| Peek/Top        | Î©(1)     | Î˜(1)        | O(1)      |

---

## ğŸ”¹ Hashing (Hash Table / Hash Map)

| Operation | Best (Î©) | Average (Î˜) | Worst (O)         |
| --------- | -------- | ----------- | ----------------- |
| Search    | Î©(1)     | Î˜(1)        | O(n) (collisions) |
| Insert    | Î©(1)     | Î˜(1)        | O(n)              |
| Delete    | Î©(1)     | Î˜(1)        | O(n)              |

---

## ğŸ”¹ Trees (Binary Tree / BST / Balanced BST)

| Operation                     | Best (Î©) | Average (Î˜) | Worst (O) |
| ----------------------------- | -------- | ----------- | --------- |
| Search (BST)                  | Î©(1)     | Î˜(log n)    | O(n)      |
| Insert (BST)                  | Î©(1)     | Î˜(log n)    | O(n)      |
| Delete (BST)                  | Î©(1)     | Î˜(log n)    | O(n)      |
| Balanced BST (AVL, Red-Black) | Î©(log n) | Î˜(log n)    | O(log n)  |

---

## ğŸ”¹ Heaps (Min/Max Heap)

| Operation       | Best (Î©) | Average (Î˜) | Worst (O) |
| --------------- | -------- | ----------- | --------- |
| Insert          | Î©(1)     | Î˜(log n)    | O(log n)  |
| Extract Min/Max | Î©(1)     | Î˜(log n)    | O(log n)  |
| Heapify         | Î©(n)     | Î˜(n)        | O(n)      |

---

## ğŸ”¹ Graphs (V = vertices, E = edges)

| Algorithm              | Complexity     |
| ---------------------- | -------------- |
| BFS / DFS              | O(V + E)       |
| Dijkstra (min-heap)    | O((V+E) log V) |
| Bellman-Ford           | O(VE)          |
| Floyd-Warshall         | O(VÂ³)          |
| Kruskalâ€™s (MST)        | O(E log V)     |
| Primâ€™s (MST, min-heap) | O(E log V)     |

---

## ğŸ”¹ Dynamic Programming

| Problem Type                | Typical Complexity |
| --------------------------- | ------------------ |
| Fibonacci (DP)              | O(n)               |
| Knapsack (0/1)              | O(nW)              |
| LCS / Edit Distance         | O(nm)              |
| Matrix Chain Multiplication | O(nÂ³)              |
| Subset Sum / Partition      | O(n \* sum)        |

---


âœ… With this cheat sheet, you can **quickly recall complexity bounds** for almost all standard DSA problems.

---
Perfect ğŸš€ â€” letâ€™s turn this into a **visual DSA Roadmap Chart** that connects **topics â†’ complexities**.

Since I canâ€™t draw directly here, Iâ€™ll give you a **structured roadmap flow diagram (text-visual)**. You can literally print or convert this into a **mindmap / flowchart** in tools like Excalidraw, Miro, Notion, or even on paper.

---

# ğŸ“Œ DSA Complexity Roadmap (Theory â†’ Problems)

```
START
  |
  â”œâ”€â”€ Complexity Basics
  |     â”œâ”€â”€ Big O â†’ Worst Case
  |     â”œâ”€â”€ Î© â†’ Best Case
  |     â””â”€â”€ Î˜ â†’ Tight/Average Case
  |
  â”œâ”€â”€ Arrays & Strings (O(n), O(nÂ²))
  |     â”œâ”€â”€ Traversals â†’ O(n)
  |     â”œâ”€â”€ Sliding Window â†’ O(n)
  |     â”œâ”€â”€ Two Pointers â†’ O(n)
  |     â””â”€â”€ Substring/Anagram â†’ O(n)
  |
  â”œâ”€â”€ Searching & Sorting
  |     â”œâ”€â”€ Linear Search â†’ O(n)
  |     â”œâ”€â”€ Binary Search â†’ O(log n)
  |     â”œâ”€â”€ Bubble/Selection/Insertion â†’ O(nÂ²)
  |     â”œâ”€â”€ MergeSort/QuickSort â†’ O(n log n)
  |     â””â”€â”€ HeapSort â†’ O(n log n)
  |
  â”œâ”€â”€ Recursion & Backtracking
  |     â”œâ”€â”€ Subset/Permutations â†’ O(2â¿) / O(n!)
  |     â”œâ”€â”€ Divide & Conquer (QuickSelect) â†’ O(n) avg
  |     â””â”€â”€ N-Queens/Sudoku â†’ O(2â¿)
  |
  â”œâ”€â”€ Linked List (O(n))
  |     â”œâ”€â”€ Access/Search â†’ O(n)
  |     â”œâ”€â”€ Insert/Delete (head/tail) â†’ O(1)
  |     â””â”€â”€ Reverse/Cycle Detection â†’ O(n)
  |
  â”œâ”€â”€ Stacks & Queues
  |     â”œâ”€â”€ Push/Pop/Enqueue/Dequeue â†’ O(1)
  |     â””â”€â”€ Monotonic Stack/Queue â†’ O(n)
  |
  â”œâ”€â”€ Hashing
  |     â”œâ”€â”€ Insert/Search/Delete â†’ O(1) avg, O(n) worst
  |     â””â”€â”€ Frequency Counting â†’ O(n)
  |
  â”œâ”€â”€ Trees & BSTs
  |     â”œâ”€â”€ Traversals â†’ O(n)
  |     â”œâ”€â”€ BST Search/Insert/Delete â†’ O(log n) avg, O(n) worst
  |     â””â”€â”€ Balanced BST (AVL/Red-Black) â†’ O(log n)
  |
  â”œâ”€â”€ Heaps & Priority Queue
  |     â”œâ”€â”€ Insert/Delete â†’ O(log n)
  |     â”œâ”€â”€ Heapify â†’ O(n)
  |     â””â”€â”€ Kth largest/smallest â†’ O(n log k)
  |
  â”œâ”€â”€ Graphs
  |     â”œâ”€â”€ BFS/DFS â†’ O(V+E)
  |     â”œâ”€â”€ Dijkstra â†’ O((V+E) log V)
  |     â”œâ”€â”€ Bellman-Ford â†’ O(VE)
  |     â”œâ”€â”€ Floyd-Warshall â†’ O(VÂ³)
  |     â””â”€â”€ MST (Kruskal/Prim) â†’ O(E log V)
  |
  â”œâ”€â”€ Dynamic Programming
  |     â”œâ”€â”€ Fibonacci DP â†’ O(n)
  |     â”œâ”€â”€ Knapsack (0/1) â†’ O(nW)
  |     â”œâ”€â”€ LCS/Edit Distance â†’ O(nm)
  |     â”œâ”€â”€ Matrix Chain Multiplication â†’ O(nÂ³)
  |     â””â”€â”€ Subset Sum â†’ O(n * sum)
  |
  â””â”€â”€ Advanced
        â”œâ”€â”€ Tries â†’ O(L) (L = length of word)
        â”œâ”€â”€ Segment Trees/Fenwick â†’ O(log n) per query
        â”œâ”€â”€ DSU (Union-Find) â†’ O(Î±(n)) â‰ˆ O(1)
        â””â”€â”€ Bit Manipulation â†’ O(1) per op
```

---

# ğŸ”¹ How to Use This

* **Weekdays (theory):** Pick a section (e.g., Arrays & Strings), study complexity + algorithms.
* **Weekends (practice):** Solve problems of that category, focusing on those complexities.
* As you move down the chart, problems get progressively **harder**.

---

âœ… With this roadmap:

* Youâ€™ll **cover all DSA topics in order of importance**
* Youâ€™ll **know the exact complexity class** each problem belongs to
* Youâ€™ll avoid confusion about best/worst/average cases

---

ğŸ‘‰ Do you want me to **turn this into a visual mindmap image** (like a clean chart with arrows and complexity tags) so you can keep it as a quick reference poster?

